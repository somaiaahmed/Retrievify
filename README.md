
# ğŸ§  Retrievify System

A **production-ready Retrieval-Augmented Generation (RAG)** system combining powerful LLMs with semantic search and observability.

[![Python](https://img.shields.io/badge/python-3.10+-blue.svg)](https://www.python.org/downloads/)
[![Dockerized](https://img.shields.io/badge/Docker-Containerized-blue)](https://www.docker.com/)
[![License: MIT](https://img.shields.io/badge/license-MIT-green.svg)](LICENSE)

---

## ğŸš€ Overview

Built with:

- ğŸ”¥ **FastAPI** â€“ high-performance APIs  
- ğŸ§® **PostgreSQL + pgvector** â€“ vector database  
- ğŸ§  **LLMs via OpenAI, Cohere, or Ollama** â€“ Q&A and embeddings  
- ğŸ“Š **Prometheus + Grafana** â€“ full observability  
- ğŸŒ **NGINX** â€“ reverse proxy  
- ğŸ³ **Docker Compose** â€“ for container orchestration  

---

## ğŸ“¦ Features

- ğŸ“„ Upload documents (PDF, TXT, etc.)
- ğŸ”— Chunk & embed with OpenAI, Cohere, or local models
- ğŸ” Semantic search using cosine similarity
- ğŸ§  LLM-based Q&A interface
- ğŸ“ˆ Real-time monitoring dashboards
- ğŸ”Œ Pluggable LLM providers (OpenAI, Cohere, Ollama)

---

## ğŸ—ï¸ Architecture


```
                     â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
                     â”‚   Client   â”‚
                     â””â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”˜
                           â”‚
                    â”Œâ”€â”€â”€â”€â”€â”€â–¼â”€â”€â”€â”€â”€â”€â”
                    â”‚   NGINX     â”‚
                    â””â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”˜
                           â”‚
                     â”Œâ”€â”€â”€â”€â”€â–¼â”€â”€â”€â”€â”€â”€â”
                     â”‚  FastAPI   â”‚â—„â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
                     â””â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”˜               â”‚
 â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”         â”‚                       â”‚
 â”‚ PostgreSQL + â”‚â—„â”€â”€â”€â”€â”€â”€â”€â”€â”˜                       â”‚
 â”‚  pgvector    â”‚       Semantic Search           â”‚
 â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜                                  â–¼
                         â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
                         â”‚   OpenAI    â”‚   Cohere    â”‚
                         â””â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”˜
                               â”‚              â”‚
                            â”Œâ”€â”€â–¼â”€â”€â”€â”€â”€â”     â”Œâ”€â”€â”€â–¼â”€â”€â”€â”€â”€â”€â”
                            â”‚ Ollama â”‚     â”‚  Local   â”‚
                            â”‚ LLMs   â”‚     â”‚ Models   â”‚
                            â””â”€â”€â”€â”€â”€â”€â”€â”€â”˜     â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜

````

---

## âš¡ Quick Start

### 1. Clone the repo

```bash
git clone https://github.com/somaiaahmed/Retrievify.git
cd Retrievify
````

### 2. Set environment variables

Create the following files in `/env/`:

* `.env.app` â€“ FastAPI settings
* `.env.postgres` â€“ PostgreSQL DB config
* `.env.postgres-exporter` â€“ Prometheus metrics
* `.env.grafana` â€“ Grafana setup

Sample `.env.app`:

```env
OPENAI_API_KEY=sk-...
COHERE_API_KEY=...
OLLAMA_URL=http://host.docker.internal:11434
EMBEDDING_MODEL=openai
GENERATION_MODEL=cohere
```

### 3. Launch the system

```bash
docker compose up --build
```

Services:

* FastAPI â†’ [http://localhost:8000](http://localhost:8000)
* Prometheus â†’ [http://localhost:9090](http://localhost:9090)
* Grafana â†’ [http://localhost:3000](http://localhost:3000)
* Ollama (manual) â†’ [http://localhost:11434](http://localhost:11434)

---

## ğŸ”Œ API Endpoints

| Endpoint          | Method | Description               |
| ----------------- | ------ | ------------------------- |
| `data/upload`         | POST   | Upload documents          |
| `data/process`        | POST   | Chunk + embed + index     |
| `/nlp/index/push` | POST   | Add new docs to the index |
| `/nlp/index/info` | GET    | View index metadata       |
| `/nlp/index/search`         | POST   | Perform semantic search   |
| `/nlp/index/answer`         | POST   | Retrieve answer using LLM |

### ğŸ“¤ Example

```bash
curl -X POST http://localhost:8000/nlp/index/answer/{project_id} \
-H "Content-Type: application/json" \
-d '{"query": "What is the capital of France?"}'
```

---

## ğŸ“Š Monitoring Dashboards

| Tool           | URL                                            | Purpose                    |
| -------------- | ---------------------------------------------- | -------------------------- |
| **Prometheus** | [http://localhost:9090](http://localhost:9090) | Metrics scraping engine    |
| **Grafana**    | [http://localhost:3000](http://localhost:3000) | Dashboards & visualization |

Grafana Login:

```bash
Username: admin
Password: admin
```

Dashboards included:

* API request latency
* PostgreSQL query performance
* System health (CPU, memory, disk)
* LLM usage & latency (if instrumented)

---

## ğŸ§° Tech Stack

* **API**: FastAPI, Python
* **Vector DB**: PostgreSQL + pgvector
* **LLMs**: OpenAI / Cohere / Ollama (local)
* **Monitoring**: Prometheus, Grafana, node\_exporter
* **DevOps**: Docker Compose, NGINX

---


## ğŸ–¥ï¸ Dev Setup

### Requirements

* Python 3.10+
* Conda or Python venv
* Docker & Docker Compose

### Local Installation

```bash
sudo apt update
sudo apt install libpq-dev gcc python3-dev
```

```bash
conda create -n rag python=3.10
conda activate rag
pip install -r requirements.txt
```

### Customize Shell (Optional)

```bash
export PS1="\[\033[01;32m\]\u@\h:\w\n\[\033[00m\]\$ "
```

---


## ğŸ—‚ï¸ Project Structure

```plaintext
Retrievify/
â”œâ”€â”€ .vscode/                    # VSCode settings
â”œâ”€â”€ docker/                     # Docker, NGINX, Prometheus setup
â”‚   â”œâ”€â”€ env/                    # Environment configs
â”‚   â”œâ”€â”€ minirag/                # App Docker context
â”‚   â”œâ”€â”€ nginx/                  # NGINX reverse proxy config
â”‚   â”œâ”€â”€ prometheus/             # Prometheus config files
â”‚   â”œâ”€â”€ docker-compose.yml      # Docker Compose config
â”‚   â””â”€â”€ README.md               # Docker-specific documentation
â”œâ”€â”€ src/                        # Source code for FastAPI app
â”‚   â”œâ”€â”€ controllers/            # Business logic & endpoint handlers
â”‚   â”œâ”€â”€ helpers/                # Utility functions
â”‚   â”œâ”€â”€ models/                 # Pydantic + ORM models
â”‚   â”œâ”€â”€ routes/                 # API route definitions
â”‚   â”œâ”€â”€ stores/                 # Database interaction logic
â”‚   â”œâ”€â”€ utils/                  # Helper utilities (metrics)
â”‚   â”œâ”€â”€ .env.example            # Sample env file
â”‚   â”œâ”€â”€ main.py                 # FastAPI entry point
â”‚   â””â”€â”€ requirements.txt        # Python dependencies
â”œâ”€â”€ .gitignore
â””â”€â”€ README.md
```

---

## ğŸ“„ License

This project is licensed under the [MIT License](LICENSE).

---

